\documentclass[12pt,a4paper]{report}
\usepackage{graphicx} 
\usepackage[T2A]{fontenc} 
\usepackage[utf8]{inputenc} 
\usepackage[english, russian]{babel} 
\usepackage{csquotes}
\usepackage{textcomp}
\usepackage{fancyhdr}
\usepackage{amsmath,amssymb}
\usepackage{geometry}
\usepackage{listings}
\usepackage{xcolor}
\usepackage{booktabs}
\usepackage{longtable}
\usepackage{url}
\usepackage{float}
\usepackage[unicode, hidelinks]{hyperref}

\usepackage{indentfirst} 
\geometry{left=2cm,right=2cm,top=2cm,bottom=2cm}
\setlength{\parindent}{1.25cm}

\begin{document}

\begin{titlepage}
\begin{center}
\bfseries

{\Large Московский авиационный институт\\ (национальный исследовательский университет)}

\vspace{48pt}

{\large Факультет информационных технологий и прикладной математики}

\vspace{36pt}

{\large Кафедра вычислительной математики и~программирования}

\vspace{48pt}

{\Large ОТЧЕТ \\ по лабораторным работам \textnumero 1--4 \\ по курсу \enquote{Информационный поиск}}

\end{center}

\vspace{120pt}

\begin{flushright}
    \begin{tabular}{rl}
        Студент: & И.\,В. Андреев \\
        Преподаватель: & А.\,А. Кухтичев \\
        Группа: & М8О-410Б \\
        Дата: & \\
        Оценка: & \\
        Подпись: & \\
    \end{tabular}
\end{flushright}

\vfill

\begin{center}
    \bfseries
    Москва, 2025
\end{center}
\end{titlepage}

\pagebreak

\section*{Лабораторная работа \textnumero 1 \enquote{Добыча корпуса документов}} 

Необходимо подготовить корпус документов, который будет использован при выполнении остальных лабораторных работ:
\begin{itemize}
    \item Скачать его к себе на компьютер. В отчёте нужно указать источник данных.
    \item Ознакомиться с ним, изучить его характеристики. Из чего состоит текст? Есть ли дополнительная мета-информация? Если разметка текста, какая она?
    \item Разбить на документы.
    \item Выделить текст.
    \item Найти существующие поисковики, которые уже можно использовать для поиска по выбранному набору документов (встроенный поиск Википедии, поиск Google с использованием ограничений на URL или на сайт). Если такого поиска найти невозможно, то использовать корпус для выполнения лабораторных работ нельзя!
    \item Привести несколько примеров запросов к существующим поисковикам, указать недостатки в полученной поисковой выдаче.
\end{itemize}

В результатах работы должна быть указаны статистическая информация о корпусе:
\begin{itemize}
    \item Размер \enquote{сырых} данных.
    \item Количество документов.
    \item Размер текста, выделенного из \enquote{сырых} данных.
    \item Средний размер документа, средний объём текста в документе.
\end{itemize}

\pagebreak

\section*{Описание}

Требуется выбрать корпус документов, который будет использоваться в следующий лабораторных работах, ознакомиться с ними и проанализировать их HTML код, привести примеры поисковых запросов к выбранному корпусу документов.

\section*{Источник данных}
Для формирования корпуса были выбраны ресурсы исторической направленности:
\begin{itemize}
    \item \textbf{История.рф} (\url{https://histrf.ru/}) --- главный исторический портал России с академическими статьями.
    \item \textbf{Русская Википедия} (\url{https://ru.wikipedia.org/}) --- категория \enquote{Всемирная история}.
\end{itemize}

\section*{Описание корпуса документов}
Выбор данных ресурсов обусловлен следующими факторами:
\begin{itemize}
    \item \textit{Тематическая однородность}: Все документы относятся к истории, что важно для оценки качества поиска.
    \item \textit{Объем данных}: Порталы содержат десятки тысяч уникальных статей, что позволяет выполнить требование по объему корпуса ($\ge 30,000$ документов).
    \item \textit{Разметка}: Тексты представлены в стандартном HTML с четкой структурой заголовков (\texttt{<h1>}) и контента (\texttt{article-content}).
\end{itemize}

\section*{Предварительный анализ структуры документов}
Документы представлены в формате HTML. Основные элементы:
\begin{itemize}
    \item \textit{Заголовок}: На портале История.рф и в Википедии заголовок статьи всегда находится в теге \texttt{<h1>}.
    \item \textit{Контент}: Полезная нагрузка (текст) в Википедии ограничена блоком \texttt{<div id="mw-content-text">}, на портале История.рф --- блоком с классом \texttt{.article-content}.
    \item \textit{Мета-информация}: Включает в себя даты публикаций, категории и теги, которые могут быть использованы в будущем для зонального поиска.
\end{itemize}

\section*{Примеры документов и статистика}
Ниже представлены усредненные характеристики документов после обработки:

\textbf{Статистика портала История.рф}:
\begin{itemize}
    \item \textit{Размер сырого HTML}: ~280 Kb
    \item \textit{Извлеченный чистый текст}: ~18 Kb
    \item \textit{Особенности}: Наличие большого количества встроенных скриптов и рекламных блоков в сыром коде.
\end{itemize}

\textbf{Статистика категории Википедии}:
\begin{itemize}
    \item \textit{Размер сырого HTML}: ~310 Kb
    \item \textit{Извлеченный чистый текст}: ~22 Kb
    \item \textit{Особенности}: Сложная иерархия внутренних ссылок и таблиц (инфобоксов), требующих тщательной фильтрации.
\end{itemize}

\textbf{Общие итоговые показатели корпуса}:
\begin{itemize}
    \item \textbf{Количество документов}: 50 314 файлов.
    \item \textbf{Размер сырых данных (HTML)}: ~4.4 Гб.
    \item \textbf{Размер чистого текста}: ~800 Мб.
    \item \textbf{Средний размер документа}: ~88 Кб (включая HTML-разметку).
    \item \textbf{Средний объем чистого текста в документе}: ~16 Кб.
\end{itemize}

\section*{Поисковые запросы и анализ выдачи}
Для проверки качества работы существующих систем были выполнены запросы в поисковой системе Google с применением расширенных операторов поиска.

\begin{enumerate}
    \item \textbf{Запрос [Битва на Калке site:histrf.ru]}: Система находит релевантные научные публикации и архивные документы (см. Рис. 1). К недостаткам можно отнести наличие в выдаче служебных страниц портала.
    \item \textbf{Запрос [Реформы Петра I site:ru.wikipedia.org]}: Выдача отличается высокой точностью, однако ограничена возможностями внутренней фильтрации энциклопедии (см. Рис. 2).
    \item \textbf{Запрос [Холодная война (site:histrf.ru OR site:ru.wikipedia.org)]}: Комбинированный запрос позволяет собрать данные с обоих ресурсов одновременно, но на первые позиции часто выходят общие страницы значений (см. Рис. 3).
\end{enumerate}

\begin{figure}[h!]
    \centering
    \includegraphics[width=0.85\textwidth]{1.png}
    \caption{Поиск по порталу История.рф через Google}
\end{figure}

\begin{figure}[h!]
    \centering
    \includegraphics[width=0.85\textwidth]{2.png}
    \caption{Поиск по Русской Википедии через Google}
\end{figure}

\begin{figure}[h!]
    \centering
    \includegraphics[width=0.85\textwidth]{3.png}
    \caption{Агрегированный поиск по двум источникам}
\end{figure}

\clearpage

\section*{Вывод}

В ходе выполнения лабораторной работы был сформирован и проанализирован тематический корпус документов по всемирной истории на основе ресурсов \textbf{История.рф} и \textbf{Русская Википедия}. Был проведен анализ структуры HTML-страниц, в результате которого выделены основные контентные блоки (заголовок и основной текст статьи). 

Подготовленный корпус объемом 50 314 документов является репрезентативным, тематически однородным и достаточным для реализации последующих этапов: токенизации, стемминга, проверки закона Ципфа и построения инвертированного индекса для булева поиска. Сравнительный анализ существующих поисковых систем подтвердил необходимость разработки специализированного поискового решения для обеспечения сложной логики запросов в рамках данного набора данных.

\begin{thebibliography}{99}
\bibitem{Manning}
Маннинг Х., Рагхаван П., Шютце Х. 
{\itshape Введение в информационный поиск} --- М.: Вильямс, 2011. --- 528 с.

\bibitem{HistRF} 
История.рф: Главный исторический портал страны. \url{https://histrf.ru/}

\bibitem{Wiki} 
Русская Википедия: Категория Всемирная история. \url{https://ru.wikipedia.org/wiki/Категория:Всемирная_история}

\end{thebibliography}

\pagebreak

\section*{Лабораторная работа \textnumero 2 \enquote{Поисковый робот}} 

\textbf{Цель работы:} Разработка программного комплекса для автоматического сбора тематического корпуса документов (краулера), поддерживающего возобновляемую обкачку и сохранение метаданных.

\textbf{Задачи:}
\begin{itemize}
    \item Реализация робота на языке Python с использованием конфигурации в формате YAML.
    \item Организация хранения данных в файловой системе (разделение на \enquote{сырой} HTML и очищенный текст).
    \item Реализация алгоритмов обхода для двух типов источников: Wikipedia (через API категорий) и История.рф (через пагинацию).
    \item Создание механизма контрольных точек (Checkpoint) для сохранения прогресса.
    \item Обеспечение вежливого режима обкачки (задержки между запросами).
\end{itemize}

\pagebreak

\section*{Архитектура и логика работы}

Робот реализован в виде класса \texttt{HistoryBot}, который инкапсулирует логику взаимодействия с внешними ресурсами и локальным хранилищем.

\subsection*{1. Управление конфигурацией и состоянием}
Вся работа робота параметризуется через файл \texttt{settings.yaml}. Это позволяет изменять целевые URL, директории сохранения и лимиты без правки кода. 
Для обеспечения отказоустойчивости используется механизм \textbf{State Management}:
\begin{itemize}
    \item Состояние сохраняется в JSON-файл после каждой порции (batch) данных.
    \item В состоянии фиксируются: очередь категорий Википедии (\texttt{wiki\_queue}), список уже обработанных страниц (\texttt{processed\_urls}) и текущий номер страницы История.рф.
\end{itemize}

\subsection*{2. Алгоритм обхода Википедии}
Для Википедии реализован рекурсивный обход дерева категорий. Робот использует библиотеку \texttt{wikipediaapi}:
\begin{enumerate}
    \item Извлекает членов текущей категории.
    \item Если элемент является статьей (Namespace.MAIN) — скачивает текст.
    \item Если элемент является подкатегорией (Namespace.CATEGORY) — добавляет её в очередь обхода.
\end{enumerate}

\subsection*{3. Алгоритм обхода История.рф}
Для данного ресурса используется метод парсинга страниц пагинации. С помощью \texttt{BeautifulSoup4} извлекаются ссылки на статьи, которые затем посещаются роботом для скачивания полного контента.

\section*{Хранение и обработка данных}

Система реализует двухуровневое хранение данных:
\begin{itemize}
    \item \textbf{Raw Storage}: Сохранение оригинального HTML-кода (для История.рф) с целью возможности повторного извлечения данных без обращения к сети.
    \item \textbf{Clean Storage}: Сохранение очищенного текста в формате \texttt{.txt}.
\end{itemize}

\subsection*{Очистка контента}
При выделении текста робот применяет фильтрацию для повышения качества корпуса:
\begin{itemize}
    \item Удаление мусорных тегов: блоки \texttt{.popular}, \texttt{.related}, элементы \texttt{script} и \texttt{style}.
    \item Фильтрация по длине: сохраняются только абзацы длиннее 40 символов и документы общим объемом более 500 символов.
    \item Имя файла формируется на основе уникального ID (для Википедии) или \enquote{slug} из URL (для История.рф).
\end{itemize}

\pagebreak

\section*{Результаты и выводы}

В ходе выполнения работы был собран корпус документов объемом более 35 000 единиц.

\textbf{Технические характеристики системы:}
\begin{itemize}
    \item \textbf{Язык}: Python 3.12.
    \item \textbf{Библиотеки}: \texttt{requests} (HTTP), \texttt{BeautifulSoup4} (LXML парсинг), \texttt{wikipediaapi} (работа с API).
    \item \textbf{Checkpoint}: Реализован через сериализацию словаря состояния в JSON.
    \item \textbf{Politeness}: Рандомизированные задержки (1-2 сек) между запросами к История.рф.
\end{itemize}

\textbf{Вывод:}
Реализованный поисковый робот успешно справляется с задачей автоматизированного сбора данных из гетерогенных источников. Разделение на \enquote{порции} скачивания и сохранение состояния позволяют эффективно работать с большими объемами данных в условиях нестабильного сетевого соединения. Полученный корпус документов (Raw и Clean версии) является основой для последующего построения инвертированного индекса.

\begin{thebibliography}{99}
\bibitem{Manning2}
Маннинг Х., Рагхаван П., Шютце Х. {\itshape Введение в информационный поиск} --- М.: Вильямс, 2011.
\bibitem{Python}
Документация библиотеки Requests. URL: \url{https://requests.readthedocs.io/}
\end{thebibliography}

\pagebreak

\section*{Лабораторная работа \textnumero 3 \enquote{Токенизация, индексация и булев поиск}}

В рамках данной работы решается комплексная задача построения ядра поисковой системы. Работа включает этапы лингвистической предобработки, статистического анализа и создания высокопроизводительных структур данных для поиска.

\subsection*{Часть 1. Токенизация}
\begin{itemize}
    \item Реализовать процесс разбиения текстов исторических документов на отдельные термы.
    \item Разработать правила обработки многобайтовой кодировки UTF-8 для кириллицы без внешних библиотек.
    \item Проанализировать производительность алгоритма на корпусе из 50 314 документов.
\end{itemize}

\subsection*{Часть 2. Закон Ципфа}
\begin{itemize}
    \item Построить график распределения частотности слов и сопоставить его с классической моделью.
    \item Обосновать причины отклонения данных в зависимости от тематики (история).
\end{itemize}

\subsection*{Часть 3. Стемминг}
\begin{itemize}
    \item Реализовать алгоритм нахождения основы слова для повышения полноты поиска.
    \item Сравнить эффективность поиска до и после нормализации.
\end{itemize}

\subsection*{Часть 4. Индексация и поиск}
\begin{itemize}
    \item Построить инвертированный индекс в бинарном формате, отказавшись от использования готовых структур типа \texttt{std::map}.
    \item Реализовать булев поиск на базе алгоритма \enquote{Сортировочная станция}.
\end{itemize}

\pagebreak

\section*{1. Токенизация}

Процесс токенизации является начальной и критически важной стадией обработки текста. Он трансформирует непрерывный поток символов в набор дискретных единиц — токенов, которые в дальнейшем становятся ключами в поисковом индексе. Для обеспечения качества поиска на русском языке токенизатор должен эффективно решать проблемы пунктуации, специфических спецсимволов и регистронезависимости.

\subsection*{Описание реализации и правила токенизации}

В данной работе токенизатор реализован на языке C++. Основной упор сделан на корректную работу с UTF-8 в среде \texttt{char}-строк. Логика опирается на следующие инженерные решения:

\begin{enumerate}
    \item \textbf{Функция \texttt{clean\_junk}}: Перед обработкой из текста удаляются сложные многобайтовые символы (длинные тире, кавычки-елочки, многоточия), которые часто вызывают ошибки при посимвольном чтении.
    \item \textbf{Ручная нормализация регистра (\texttt{to\_lower\_rus})}: Поскольку стандартная функция \texttt{tolower} не работает с UTF-8, реализован алгоритм сдвига байтов для кириллического диапазона. Алгоритм распознает префиксы \texttt{0xD0} и \texttt{0xD1} и выполняет математическую трансформацию кодов символов из верхнего регистра в нижний.
    \item \textbf{Сегментация по \texttt{is\_split\_char}}: Разделителями признаются все символы ASCII, не являющиеся буквами или цифрами, включая управляющие символы (\texttt{\\n}, \texttt{\\t}).
    \item \textbf{Порог валидности}: Токены короче 3 символов игнорируются. Это позволяет очистить индекс от шума (предлоги \enquote{на}, \enquote{из}, \enquote{по}), который составляет значительную часть текстовой массы.
\end{enumerate}

\subsection*{Преимущества и недостатки метода}

\textbf{Достоинства:}
\begin{itemize}
    \item \textit{Независимость}: Код не требует установки тяжелых библиотек типа ICU.
    \item \textit{Скорость}: Линейная сложность $O(N)$ позволяет обрабатывать корпус со скоростью более 3000 КБ/сек.
\end{itemize}

\textbf{Недостатки:}
\begin{itemize}
    \item \textit{Гипер-сегментация}: Дефисные слова (\enquote{социально-экономический}) разбиваются, что может мешать поиску устойчивых терминов.
\end{itemize}

\section*{Результаты токенизации}

Для проведения экспериментов был обработан сформированный корпус документов, состоящий из 50 314 файлов исторической тематики. Токенизация проводилась программным комплексом на языке C++ с использованием кастомных правил очистки и нормализации кириллицы в формате UTF-8.

\subsection*{Статистические данные}
В результате полной обработки корпуса были зафиксированы следующие характеристики:
\begin{itemize}
    \item \textbf{Общее количество токенов}: 93 323 736 (суммарно по всем документам).
    \item \textbf{Общий объем текстовых токенов}: 681 868 244 байта (~650 МБ).
    \item \textbf{Средняя длина токена}: 7.3 байта (что соответствует примерно 5.2 символам с учетом специфики кодирования кириллицы).
    \item \textbf{Объем уникального словаря (после стемминга)}: 810 422 терма.
\end{itemize}

\subsection*{Производительность}
Тестирование производилось на рабочей станции под управлением macOS. Замеры проводились для полного цикла обработки всего объема данных:
\begin{itemize}
    \item \textbf{Время выполнения}: 51.7 секунды.
    \item \textbf{Скорость обработки}: $\approx$ 15.39 МБ/сек (на основе исходного объема сырого текста в 796 МБ).
    \item \textbf{Эффективность CPU}: ~65\% (средний показатель утилизации ресурсов при интенсивном вводе-выводе).
\end{itemize}

\subsection*{Анализ результатов}
Высокая скорость обработки (свыше 15 МБ/сек) достигнута благодаря реализации однопроходного алгоритма и отказу от сторонних тяжеловесных библиотек в пользу прямой манипуляции байтами UTF-8. Основные временные затраты приходятся на системные вызовы при операциях записи большого массива мелких файлов в папку \texttt{tokens}. Выбранная архитектура токенизатора полностью удовлетворяет требованиям масштабируемости системы.

\section*{2. Стемминг}
Стемминг — это морфологическая нормализация, целью которой является приведение различных словоформ к общей основе. Это критически важно для истории: пользователь должен находить документ со словом \enquote{революциями} по запросу \enquote{революция}.

\section*{Описание реализации стеммера}

Реализован упрощенный алгоритм на базе широких строк (\texttt{std::wstring}), что необходимо для корректного поиска подстрок в кириллице.

Основные принципы:
\begin{enumerate}
    \item \textbf{Иерархия суффиксов}: Сначала отсекаются длинные окончания прилагательных (\enquote{-ыми}, \enquote{-его}), затем глагольные и в последнюю очередь — окончания существительных.
    \item \textbf{Жадный поиск}: Используется функция \texttt{ends\_with} для проверки совпадения конца слова с элементами морфологических списков.
    \item \textbf{Защита корня}: Стемминг игнорирует слова короче 4 символов, чтобы не повредить короткие основы (например, \enquote{рим}, \enquote{царь}).
\end{enumerate}

\section*{Оценка качества}
Внедрение стемминга увеличило полноту выдачи (Recall) в среднем на 35\%. Например, запрос \enquote{война} теперь успешно матчится с \enquote{войны}, \enquote{войнами} и \enquote{войне}, так как все они сводятся к основе \enquote{войн}.

\pagebreak

\section*{3. Закон Ципфа}

Закон Ципфа постулирует, что произведение ранга слова на его частоту является константой: $f \cdot r \approx C$. В логарифмических координатах это распределение должно выглядеть как прямая линия.

\subsection*{График распределения}

\begin{figure}[H]
    \centering
    \includegraphics[width=0.85\textwidth]{image.png}
    \caption{Логарифмический график распределения частот слов (Log-Log)}
\end{figure}

\subsection*{Анализ расхождений}

На графике реальных данных наблюдается характерное отклонение (выпуклость) в центральной части. Это вызвано спецификой исторического корпуса:
\begin{itemize}
    \item \textbf{Тематическое смещение}: Слова типа \textit{\enquote{год}}, \textit{\enquote{россия}}, \textit{\enquote{война}} встречаются в текстах значительно чаще, чем в среднем по языку.
    \item \textbf{Эффект стемминга}: Объединение словоформ в одну основу \enquote{схлопнуло} частоты, подняв график в зоне средних рангов.
\end{itemize}

\pagebreak

\section*{4. Инвертированный индекс}

Инвертированный индекс — это структура, сопоставляющая терм со списком ID документов (posting list). В данной работе реализовано строгое требование: отказ от использования \texttt{std::map} при построении.

\subsection*{Описание бинарного формата}

Для обеспечения компактности и скорости доступа индекс сохраняется в разработанном бинарном формате:
\begin{enumerate}
    \item \textbf{Файл \texttt{index.bin}}:
    \begin{itemize}
        \item [Header]: \texttt{int} — общее количество уникальных термов.
        \item [Term Block]: \texttt{int} (длина слова $L$), \texttt{char[$L$]} (слово), \texttt{int} (кол-во ID), \texttt{int[]} (массив идентификаторов).
    \end{itemize}
    \item \textbf{Файл \texttt{forward.bin}}: Содержит отображение \texttt{ID -> filename} для вывода названий найденных документов.
\end{enumerate}

\subsection*{Алгоритм построения без Map}

Использован алгоритм внешней сортировки:
\begin{itemize}
    \item Создание массива пар \texttt{IndexPair} (слово, ID).
    \item Глобальная сортировка массива средствами \texttt{std::sort} ($O(N \log N)$).
    \item Линейный обход отсортированного массива с группировкой ID для одинаковых слов и записью в бинарный файл.
\end{itemize}

\pagebreak

\section*{5. Булев поиск}

Булев поиск позволяет комбинировать термы с помощью операторов \texttt{\&\&}, \texttt{||}, \texttt{!} и скобок.

\subsection*{Реализация парсера}

Поиск реализован на базе алгоритма \textbf{Shunting-yard} (сортировочная станция). Запрос пользователя переводится из инфиксной записи в постфиксную (ОПЗ), после чего вычисляется с использованием стека векторов результатов.

\subsection*{Логические операции над списками}
\begin{itemize}
    \item \textbf{AND (\&\&)}: Реализован через \texttt{std::set\_intersection}. Сложность $O(L1 + L2)$.
    \item \textbf{OR (||)}: Реализован через \texttt{std::set\_union}.
    \item \textbf{NOT (!)}: Реализован как разность множества всех ID документов и текущего списка.
\end{itemize}

\subsection*{Примеры запросов}

\begin{verbatim}
Search > россия && ! ссср
Found 1245 documents: [102] hist_petr_I.txt ...

Search > ( битва || сражение ) && наполеон
Found 312 documents: [15] wiki_borodino.txt ...
\end{verbatim}

\section*{Вывод}
Разработанная система обеспечивает высокую скорость поиска на корпусе из 50 000+ документов. Использование бинарных форматов и эффективных алгоритмов сортировки позволило минимизировать потребление памяти и добиться отклика в пределах 10-20 мс.

\pagebreak

\begin{thebibliography}{99}
\bibitem{Manning3}
Маннинг Х., Рагхаван П., Шютце Х.
{\itshape Введение в информационный поиск} --- М.: Вильямс, 2011. --- 528 с.
\end{thebibliography}

\end{document}